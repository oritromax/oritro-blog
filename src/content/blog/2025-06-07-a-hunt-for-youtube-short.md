---
title: A Hunt for a YouTube Short
date: 2025-06-07 14:43:11
tags:
    - youtube
    - shorts
    - AI
categories: 
    - ai 
description: This so-called hunt gave me a different perspective on how hyped up AI is and how data poisoning is obscuring the results
---

I am a big fan of everything mystery, detective, and crime drama. Have been for a while. In my off time, I'm always watching or looking for the next one. 

I've watched hundreds of trailers of shows in that genre, and obviously, YouTube has a pretty good idea of what I like and don't like.

### Where It Started 

I was just browsing through YouTube Shorts while taking a coffee break and came across a short, an intriguing clip from a movie or TV show.

![Preview of the short](/static/2025/06/short-preview.jpeg)

If you look at the image, you can see a few things that indicate this is a view-farming account. The uploader likely has no idea what show or movie this is from. They probably found it on another YouTube Short or TikTok and uploaded it with an AI voiceover and an annoying middle-screen subtitle to match.

### Story 

> A soldier comes home to find his house has been occupied by some party people. They claim the soldier isn't the owner of the house. A woman from the party claims it belongs to her boyfriend. Finally, the police are called and confirm the house is legally owned by the soldier. While searching, they find the dead body of the so-called _boyfriend_ in the basement. The dead boyfriend had a fake identity and claimed this house belonged to him. 

That's it. That’s where the short ends. Being a fan of murder mysteries, I was intrigued. I wanted to see where the story goes. But as you can see from the short, there's no mention of where it's from. The comments were disabled, so that didn’t help either. 

### The Hunt

In this day of overwhelming connectivity, AI, and massive data collection, how hard could it be to find one series? 

Boy, was I wrong. Here's how I initially approached it: I took a screenshot and went to Google Image Search—the same image you can see above. I figured Google would at least be able to identify the actor.

***It Couldn't.***

![Google Search Result](/static/2025/06/chrome_FdoDt0SFxf.png)

It found the same short uploaded by a few other people—all with the same issues: comments disabled, annoying AI subtitles, and no clue about the source.

**Gemini**

Surely Gemini could help. It has the knowledge base of the entire Google search engine (_or so I thought_).

First, I gave Gemini the exact context I saw in the short—a written description.

![Gemini with written story description](/static/2025/06/chrome_wTJp1ivW5V.png)

I intentionally kept it vague to see if Gemini could pick it up.

**Warrior?**

It picked a movie called *Warrior*, which was hilarious. I'm a big fan of Tom Hardy and have watched everything he’s ever done. I saw *Warrior*, and it has absolutely nothing to do with this. 

But I admit, my prompt was definitely vague. So I tried again.

![Gemini with broader text description of the story](/static/2025/06/chrome_Ri9nyzB4nZ.png)

_This was a voice prompt, so a few words got mangled._

It failed miserably again. The answer it came up with was, again, completely wrong.

**ChatGPT**

So I tried the OG—ChatGPT.

![ChatGPT with story description as prompt](/static/2025/06/chrome_YpKr58j79h.png)

I first went with the description of the story, and something interesting happened. In the screenshot above, you can see it mentioned two links. 

In a very wrong way, it's correct—those are the clips where this story unfolds. The YouTube link is the exact clip I saw that drove me down this rabbit hole.

But it failed to reference which movie or TV show the clip is from. Not great.

> But keep this ChatGPT answer in mind—it will be important later. 

---

At this point, after the AI failure, I decided to do some manual investigation.

### The Manual Hunt

In the clip, I recognized an actor I’ve seen before in many places. He played the father of __Sarah Walker__ in __Chuck__.

> Don’t care what anyone says—*Chuck* is one of the best series I’ve ever seen from a comedic perspective with a slight hint of thriller and spy-genre. <https://en.wikipedia.org/wiki/Chuck_(TV_series)>

After checking IMDb, I found the actor’s name is __Gary Cole__.

Looking into his IMDb list of credits, I immediately noticed *NCIS*.

A few things clicked:

- Military man
- Murder investigation 
- People dressed in blue windbreakers in the video

Anyone who has ever watched a good procedural investigation fiction show knows *NCIS*.

So I tried again with Gemini, this time using a more restricted query.

![Second attempt with Gemini, with restricted prompt](/static/2025/06/chrome_43E9jheRZo.png)

It immediately found the episode.

Two things to note here:

- The AI narrator of the short mistakenly said the fake owner's name is Harry—it’s *Hal*.
- My prompt was very narrow, but it worked because of how specific it was.

### AI Knowledge Poisoning

I mentioned the term "AI poisoning." Some might wonder why. It's not exactly the right term—it should be "LLM knowledge poisoning," but I digress.

What happened here, especially with ChatGPT, is what’s commonly known online as a circle jerk. I asked it to find information about something, and it kept referencing the same clip I saw, because of how many times that clip has been uploaded without attribution. This gave it a heavier weight in search results, making it the de facto source of truth.

Instead of looking for a movie or show with a similar storyline, it kept going back to those same videos because they had the “right” caption. 

__What happened with Gemini?__ I have no idea. It kept suggesting movies with zero soldiers or relevance to the story.

And that brings us to the end of this saga. Is this important? Nope. But I had to document this for the sake of history—how re-uploading the same video with low-effort AI-generated subtitles can elevate misinformation to the top, obscuring the actual truth.

*NCIS* is popular enough that it should’ve been the first result—even if I had the name slightly wrong. It wasn’t.

Something to think about, isn’t it?